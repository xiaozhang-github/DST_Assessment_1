---
title: "dst_assessment1_naiveBayes"
author: "Wenqi Fang"
date: "19/11/2020"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Naive Bayes classifiers are a family of simple "probabilistic classifiers" based on applying Bayes' theorem with strong independence assumptions between the features. 


## R part of assessment

## Header content


required libraries:
```{r}
if (!require("e1071")) install.packages("e1071")
if (!require("gmodels")) install.packages("gmodels")
if (!require("caret")) install.packages("caret")
library(e1071) # for training the data
library(gmodels) # For evaluating the model performance
library(caret) # For evaluating the model performance
```


load and name the data:
```{r}
kdd.train <- read.csv(file="D:\\SSS\\MSC\\dst\\data\\ass1\\new\\new\\kddcup99_train.csv", header=F) #training data
kdd.test1 <- read.csv(file="D:\\SSS\\MSC\\dst\\data\\ass1\\new\\new\\kddcup99_test.csv", header=F) #testing data
kdd.test2 <- read.csv(file="D:\\SSS\\MSC\\dst\\data\\ass1\\new\\new\\kddcup99_test2.csv", header=F) #another testing data for more realistic 
kddnames<-read.csv(file="D:\\SSS\\MSC\\dst\\data\\kddcup.names.txt")
colnames(kdd.train)=c(kddnames[,1],"label") 
colnames(kdd.test1)=c(kddnames[,1],"label")
colnames(kdd.test2)=c(kddnames[,1],"label")
```

coverts label column to factor:
```{r}
kdd.train$label<-as.factor(kdd.train$label)
kdd.test1$label<-as.factor(kdd.test1$label)
kdd.test2$label<-as.factor(kdd.test2$label)
head(kdd.train)
head(kdd.test1)
head(kdd.test2)
```



## train a model on data

```{r}
model<-naiveBayes(label~., data=kdd.train) #use the naivebayes() function to train data
pred1<-predict(model,kdd.test1[-42]) #classify test data
head(pred1)
```

classify the second test data :
```{r}
pred2<-predict(model,kdd.test2[-42])
head(pred2)
```


## evaluate the model performance

```{r}
CrossTable(x=kdd.test1$label,y=pred1)
CrossTable(x=kdd.test2$label,y=pred2)
```
evaluate the model performance by confusionmatrix
```{r}
confusionMatrix(pred1,kdd.test1$label)
confusionMatrix(pred2,kdd.test2$label)
```

accuracy.pred1=87.66%;
accuracy.pred2=73.97%.


## another try


```{r}
library(caret)
```

```{r}
intraining<-createDataPartition(kddata$label,p=.7,list = F)
training<-kddata[intraining,]
testing<-kddata[-intraining,]
```


```{r}
fitcontrol<-trainControl(method = "repeatedcv",number = 10,repeats = 10,classProbs = TRUE)
```




```{r}
library(klaR)
training$label<-as.factor(training$label)
nbfit<-train(label~.,data=training,method="nb",trcontrol=fitcontrol,metric="ROC")
nbfit
```



```{r}
install.packages("gmodels")
```

```{r}
library(gmodels)
```




```{r}
library(factoextra)
cor(kdd.train)
pca=princomp(kdd.train,cor=F,scores=T)
screeplot(pca,type="lines")
```

```{r}
pca$loadings
```

```{r}
jitter(kdd.train.unlabel$src_bytes,amount=0)
jitter(kdd.train.unlabel$dst_bytes,amount=0)
jitter(kdd.test$src_bytes,amount=0)
jitter(kdd.test$dst_bytes,amount=0)
jitter(kdd.train.unlabel$count,amount=0)
jitter(kdd.test$count,amount=0)
kdd.test.pred<-knn(train=kdd.train.unlabel,test=kdd.test,cl=kdd.train.labels,k=1,use.all = F)
```
